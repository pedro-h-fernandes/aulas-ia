{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8313fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from river import feature_extraction, linear_model, compose\n",
    "from river import preprocessing\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbfc0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 1. Carregar o dataset\n",
    "# ==========================\n",
    "df = pd.read_excel(\"movies_database.xlsx\", engine='openpyxl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0720b329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        object\n",
       "title                     object\n",
       "link                      object\n",
       "year                     float64\n",
       "duration                  object\n",
       "rating_mpa                object\n",
       "rating_imdb              float64\n",
       "vote                     float64\n",
       "budget                   float64\n",
       "gross_world_wide         float64\n",
       "gross_us_canada          float64\n",
       "gross_opening_weekend    float64\n",
       "director                  object\n",
       "writer                    object\n",
       "star                      object\n",
       "genre                     object\n",
       "country_origin            object\n",
       "filming_location          object\n",
       "production_company        object\n",
       "language                  object\n",
       "win                      float64\n",
       "nomination               float64\n",
       "oscar                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c90ee225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating_imdb'] = df['rating_imdb'].astype(float)\n",
    "df['year'] = df['year'].fillna(0).astype(int)\n",
    "df['gross_world_wide'] = df['gross_world_wide'].astype(float)\n",
    "df['budget'] = df['budget'].astype(float)\n",
    "df['gross_opening_weekend'] = df['gross_opening_weekend'].astype(float)\n",
    "df['oscar'] = df['oscar'].fillna(0).astype(int)\n",
    "df['nomination'] = df['nomination'].fillna(0).astype(int)\n",
    "df['duration'] = df['duration'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40127719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para converter o tempo em minutos\n",
    "def converter_tempo_para_minutos(tempo_str):\n",
    "    if pd.isna(tempo_str) or tempo_str.lower() == 'nan':\n",
    "        return None\n",
    "    partes = tempo_str.replace('h', '').replace('m', '').split()\n",
    "    try:\n",
    "        horas = int(partes[0]) if partes[0] else 0\n",
    "    except ValueError:\n",
    "        horas = 0\n",
    "    try:\n",
    "        minutos = int(partes[1]) if len(partes) > 1 else 0\n",
    "    except (ValueError, IndexError):\n",
    "        minutos = 0\n",
    "    return (horas * 60) + minutos\n",
    "\n",
    "# Aplique a função à coluna 'duration' e crie uma nova coluna 'duration_min'\n",
    "df['duration_min'] = df['duration'].apply(converter_tempo_para_minutos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15e083a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 2. Definir intents e exemplos de perguntas\n",
    "# ==========================\n",
    "perguntas = [\n",
    "    \"Qual o filme mais bem avaliado?\",\n",
    "    \"Qual filme tem a melhor nota?\",\n",
    "    \"Me diga o filme mais bem avaliado.\",\n",
    "    \"Qual o filme com maior bilheteria mundial?\",\n",
    "    \"Qual filme arrecadou mais dinheiro?\",\n",
    "    \"Qual filme teve maior receita?\",\n",
    "    \"Quem é o diretor de Titanic?\",\n",
    "    \"Quem dirigiu Titanic?\",\n",
    "    \"Qual o nome do diretor do filme Titanic?\",\n",
    "    \"Quantos Oscars ganhou Avatar?\",\n",
    "    \"Quantos prêmios Oscar o filme Avatar recebeu?\",\n",
    "    \"Avatar ganhou algum Oscar?\",\n",
    "    \"Qual o gênero do filme Interstellar?\",\n",
    "    \"Me diga o gênero de Interstellar.\",\n",
    "    \"Interstellar é de qual gênero?\",\n",
    "    \"Qual o filme com mais indicações ao Oscar?\",\n",
    "    \"Qual filme recebeu mais indicações ao Oscar?\",\n",
    "    \"Filme com maior número de indicações ao Oscar?\",\n",
    "    \"Qual o filme mais longo?\",\n",
    "    \"Qual é o filme com maior duração?\",\n",
    "    \"Me diga o filme mais longo da lista.\",\n",
    "    \"Qual o filme mais recente?\",\n",
    "    \"Qual filme foi lançado mais recentemente?\",\n",
    "    \"Me diga o filme mais novo.\"\n",
    " ]\n",
    "intencoes = [\n",
    "    \"melhor_nota\",\n",
    "    \"melhor_nota\",\n",
    "    \"melhor_nota\",\n",
    "    \"maior_bilheteria\",\n",
    "    \"maior_bilheteria\",\n",
    "    \"maior_bilheteria\",\n",
    "    \"diretor\",\n",
    "    \"diretor\",\n",
    "    \"diretor\",\n",
    "    \"oscar\",\n",
    "    \"oscar\",\n",
    "    \"oscar\",\n",
    "    \"genero\",\n",
    "    \"genero\",\n",
    "    \"genero\",\n",
    "    \"mais_indicacoes\",\n",
    "    \"mais_indicacoes\",\n",
    "    \"mais_indicacoes\",\n",
    "    \"maior_duracao\",\n",
    "    \"maior_duracao\",\n",
    "    \"maior_duracao\",\n",
    "    \"filme_recente\",\n",
    "    \"filme_recente\",\n",
    "    \"filme_recente\"\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4835205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 3. Criar modelo com River\n",
    "# ==========================\n",
    "# Criação do modelo de classificação de intenções usando River\n",
    "modelo = compose.Pipeline(\n",
    "    (\"bow\", feature_extraction.BagOfWords(on=\"pergunta\", lowercase=True, strip_accents=True, ngram_range=(1, 2))),\n",
    "    (\"clf\", linear_model.LogisticRegression())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d36b7d52",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'melhor_nota'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pergunta, intent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(perguntas, intencoes):\n\u001b[0;32m      2\u001b[0m     X \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpergunta\u001b[39m\u001b[38;5;124m\"\u001b[39m: pergunta}\n\u001b[1;32m----> 3\u001b[0m     modelo \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\river\\compose\\pipeline.py:474\u001b[0m, in \u001b[0;36mPipeline.learn_one\u001b[1;34m(self, x, y, **params)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# Here the step is not a transformer, and it's supervised, such as a LinearRegression.\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# This is usually the last step of the pipeline.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m step\u001b[38;5;241m.\u001b[39m_supervised:\n\u001b[1;32m--> 474\u001b[0m     \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# Here the step is not a transformer, and it's unsupervised, such as a KMeans. This\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# is also usually the last step of the pipeline.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m     step\u001b[38;5;241m.\u001b[39mlearn_one(x\u001b[38;5;241m=\u001b[39mx)\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\river\\linear_model\\base.py:164\u001b[0m, in \u001b[0;36mGLM.learn_one\u001b[1;34m(self, x, y, w)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn_one\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learn_mode(x):\n\u001b[1;32m--> 164\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval_gradient_one\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\river\\linear_model\\base.py:110\u001b[0m, in \u001b[0;36mGLM._fit\u001b[1;34m(self, x, y, w, get_grad)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mlook_ahead(w\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weights)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Calculate the gradient\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m gradient, loss_gradient \u001b[38;5;241m=\u001b[39m \u001b[43mget_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Update the intercept\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_intercept_update(loss_gradient)\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\river\\linear_model\\base.py:148\u001b[0m, in \u001b[0;36mGLM._eval_gradient_one\u001b[1;34m(self, x, y, w)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_eval_gradient_one\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: \u001b[38;5;28mdict\u001b[39m, y: \u001b[38;5;28mfloat\u001b[39m, w: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m--> 148\u001b[0m     loss_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_dot_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m     loss_gradient \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m w\n\u001b[0;32m    150\u001b[0m     loss_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\n\u001b[0;32m    151\u001b[0m         utils\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mclamp(loss_gradient, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_gradient, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_gradient)\n\u001b[0;32m    152\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\river\\optim\\losses.py:350\u001b[0m, in \u001b[0;36mLog.gradient\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m    348\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_neg\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 350\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m z \u001b[38;5;241m=\u001b[39m y_pred \u001b[38;5;241m*\u001b[39m y_true\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m z \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m18.0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'melhor_nota'"
     ]
    }
   ],
   "source": [
    "for pergunta, intent in zip(perguntas, intencoes):\n",
    "    X = {\"pergunta\": pergunta}\n",
    "    modelo = modelo.learn_one(X, intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar as intenções como números usando um dicionário\n",
    "# intent_to_num = {intent: idx for idx, intent in enumerate(intencoes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb0dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta: Qual o filme mais bem avaliado? | Intenção: melhor_nota | Intenção codificada: 2\n",
      "Pergunta: Qual filme tem a melhor nota? | Intenção: melhor_nota | Intenção codificada: 2\n",
      "Pergunta: Me diga o filme mais bem avaliado. | Intenção: melhor_nota | Intenção codificada: 2\n",
      "Pergunta: Qual o filme com maior bilheteria mundial? | Intenção: maior_bilheteria | Intenção codificada: 5\n",
      "Pergunta: Qual filme arrecadou mais dinheiro? | Intenção: maior_bilheteria | Intenção codificada: 5\n",
      "Pergunta: Qual filme teve maior receita? | Intenção: maior_bilheteria | Intenção codificada: 5\n",
      "Pergunta: Quem é o diretor de Titanic? | Intenção: diretor | Intenção codificada: 8\n",
      "Pergunta: Quem dirigiu Titanic? | Intenção: diretor | Intenção codificada: 8\n",
      "Pergunta: Qual o nome do diretor do filme Titanic? | Intenção: diretor | Intenção codificada: 8\n",
      "Pergunta: Quantos Oscars ganhou Avatar? | Intenção: oscar | Intenção codificada: 11\n",
      "Pergunta: Quantos prêmios Oscar o filme Avatar recebeu? | Intenção: oscar | Intenção codificada: 11\n",
      "Pergunta: Avatar ganhou algum Oscar? | Intenção: oscar | Intenção codificada: 11\n",
      "Pergunta: Qual o gênero do filme Interstellar? | Intenção: genero | Intenção codificada: 14\n",
      "Pergunta: Me diga o gênero de Interstellar. | Intenção: genero | Intenção codificada: 14\n",
      "Pergunta: Interstellar é de qual gênero? | Intenção: genero | Intenção codificada: 14\n",
      "Pergunta: Qual o filme com mais indicações ao Oscar? | Intenção: mais_indicacoes | Intenção codificada: 17\n",
      "Pergunta: Qual filme recebeu mais indicações ao Oscar? | Intenção: mais_indicacoes | Intenção codificada: 17\n",
      "Pergunta: Filme com maior número de indicações ao Oscar? | Intenção: mais_indicacoes | Intenção codificada: 17\n",
      "Pergunta: Qual o filme mais longo? | Intenção: maior_duracao | Intenção codificada: 20\n",
      "Pergunta: Qual é o filme com maior duração? | Intenção: maior_duracao | Intenção codificada: 20\n",
      "Pergunta: Me diga o filme mais longo da lista. | Intenção: maior_duracao | Intenção codificada: 20\n",
      "Pergunta: Qual o filme mais recente? | Intenção: filme_recente | Intenção codificada: 23\n",
      "Pergunta: Qual filme foi lançado mais recentemente? | Intenção: filme_recente | Intenção codificada: 23\n",
      "Pergunta: Me diga o filme mais novo. | Intenção: filme_recente | Intenção codificada: 23\n"
     ]
    }
   ],
   "source": [
    "# # Treinar com perguntas e intenções iniciais\n",
    "# for pergunta, intent in zip(perguntas, intencoes):\n",
    "#     # intent_encoded = intent_to_num[intent]\n",
    "#     modelo.learn_one(pergunta, intent_encoded)\n",
    "#     print(f\"Pergunta: {pergunta} | Intenção: {intent} | Intenção codificada: {intent_encoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fbfc09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 4. Funções auxiliares\n",
    "# ==========================\n",
    "def encontrar_filme(titulo):\n",
    "    \"\"\"Retorna o filme mais parecido com o nome fornecido\"\"\"\n",
    "    titulos = df['title'].tolist()\n",
    "    candidato = difflib.get_close_matches(titulo, titulos, n=1, cutoff=0.6)\n",
    "    return candidato[0] if candidato else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "614ff047",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_intent = {v: k for k, v in intent_to_num.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responder(pergunta):\n",
    "    print(pergunta)\n",
    "    # Predizer intenção\n",
    "    # intent = modelo.predict([pergunta])[0]\n",
    "    intent_num = modelo.predict_one(pergunta)\n",
    "    intent = num_to_intent.get(intent_num, None)\n",
    "    print(f\"Pergunta: {pergunta} | Intenção: {intent}\")\n",
    "    \n",
    "    # Respostas baseadas na intenção\n",
    "    if intent == \"melhor_nota\":\n",
    "        filme = df.loc[df['rating_imdb'].idxmax()]\n",
    "        return f\"O filme mais bem avaliado é '{filme['title']}' com nota {filme['rating_imdb']} no IMDb.\"\n",
    "    \n",
    "    elif intent == \"maior_bilheteria\":\n",
    "        filme = df.loc[df['gross_world_wide'].idxmax()]\n",
    "        return f\"O filme com maior bilheteria mundial é '{filme['title']}' com ${filme['gross_world_wide']:,} arrecadados.\"\n",
    "    \n",
    "    elif intent == \"diretor\":\n",
    "        palavras = pergunta.split()\n",
    "        for p in palavras:\n",
    "            filme = encontrar_filme(p)\n",
    "            if filme:\n",
    "                diretor = df.loc[df['title'] == filme, 'director'].values[0]\n",
    "                return f\"O diretor de '{filme}' é {diretor}.\"\n",
    "        return \"Não encontrei o filme na base de dados.\"\n",
    "    \n",
    "    elif intent == \"oscar\":\n",
    "        palavras = pergunta.split()\n",
    "        for p in palavras:\n",
    "            filme = encontrar_filme(p)\n",
    "            if filme:\n",
    "                oscars = df.loc[df['title'] == filme, 'oscar'].values[0]\n",
    "                return f\"O filme '{filme}' ganhou {oscars} Oscars.\"\n",
    "        return \"Não encontrei informações sobre Oscars para esse filme.\"\n",
    "    \n",
    "    elif intent == \"genero\":\n",
    "        palavras = pergunta.split()\n",
    "        for p in palavras:\n",
    "            filme = encontrar_filme(p)\n",
    "            if filme:\n",
    "                genero = df.loc[df['title'] == filme, 'genre'].values[0]\n",
    "                return f\"O gênero do filme '{filme}' é {genero}.\"\n",
    "        return \"Não encontrei o gênero do filme.\"\n",
    "    \n",
    "    elif intent == \"mais_indicacoes\":\n",
    "        filme = df.loc[df['nomination'].idxmax()]\n",
    "        return f\"O filme com mais indicações ao Oscar é '{filme['title']}' com {filme['nomination']} indicações.\"\n",
    "    \n",
    "    elif intent == 20:\n",
    "        filme = df.loc[df['duration_min'].idxmax()]\n",
    "        return f\"O filme mais longo é '{filme['title']}' com duração de {filme['duration_min']} minutos.\"\n",
    "    \n",
    "    elif intent == \"filme_recente\":\n",
    "        filme = df.loc[df['year'].idxmax()]\n",
    "        return f\"O filme mais recente é '{filme['title']}', lançado em {filme['year']}.\"\n",
    "    \n",
    "    return \"Desculpe, não consegui entender a sua pergunta.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d52d0daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bem-vindo ao sistema de filmes! Pergunte sobre os filmes ou digite 'sair' para encerrar.\n",
      "qual o filme mais longo?\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaindo...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m resposta \u001b[38;5;241m=\u001b[39m \u001b[43mresponder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpergunta_usuario\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(resposta)\n",
      "Cell \u001b[1;32mIn[58], line 4\u001b[0m, in \u001b[0;36mresponder\u001b[1;34m(pergunta)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(pergunta)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Predizer intenção\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m intent \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(pergunta)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# intent_num = modelo.predict_one(pergunta)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# intent = num_to_intent.get(intent_num, None)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# print(f\"Pergunta: {pergunta} | Intenção: {intent}\")\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Respostas baseadas na intenção\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m intent \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmelhor_nota\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 5. Loop de interação\n",
    "# ==========================\n",
    "print(\"Bem-vindo ao sistema de filmes! Pergunte sobre os filmes ou digite 'sair' para encerrar.\")\n",
    "\n",
    "while True:\n",
    "    pergunta_usuario = input(\"\\nSua pergunta: \")\n",
    "\n",
    "    if pergunta_usuario.lower() == \"sair\":\n",
    "        print(\"Saindo...\")\n",
    "        break\n",
    "\n",
    "    resposta = responder(pergunta_usuario)\n",
    "    print(resposta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb402eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
